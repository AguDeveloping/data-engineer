{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proceso ETL Completo\n",
    "\n",
    "Este notebook muestra cu00f3mo implementar un proceso ETL (Extract, Transform, Load) completo utilizando nuestro framework.\n",
    "\n",
    "## Configuraciu00f3n del entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Agregar el directorio rau00edz al path para poder importar los mu00f3dulos\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "\n",
    "# Importar mu00f3dulos ETL\n",
    "from src.etl.extract import extract_from_csv, extract_from_api\n",
    "from src.etl.transform import transform_raw_data\n",
    "from src.etl.load import load_to_final_table\n",
    "\n",
    "# Importar utilidades\n",
    "from src.utils.database import engine, execute_query\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import text\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Configurar visualizaciones\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extracciu00f3n (Extract)\n",
    "\n",
    "Primero, vamos a crear algunos datos de ejemplo y guardarlos en un archivo CSV para simular la extracciu00f3n de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>producto_id</th>\n",
       "      <th>cantidad</th>\n",
       "      <th>precio_unitario</th>\n",
       "      <th>categoria</th>\n",
       "      <th>fecha_venta</th>\n",
       "      <th>region</th>\n",
       "      <th>total_venta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>367.21</td>\n",
       "      <td>Electru00f3nica</td>\n",
       "      <td>2025-07-08</td>\n",
       "      <td>Este</td>\n",
       "      <td>1468.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93</td>\n",
       "      <td>14</td>\n",
       "      <td>387.92</td>\n",
       "      <td>Deportes</td>\n",
       "      <td>2025-07-08</td>\n",
       "      <td>Centro</td>\n",
       "      <td>5430.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>46.28</td>\n",
       "      <td>Juguetes</td>\n",
       "      <td>2025-07-08</td>\n",
       "      <td>Este</td>\n",
       "      <td>833.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72</td>\n",
       "      <td>9</td>\n",
       "      <td>185.65</td>\n",
       "      <td>Electru00f3nica</td>\n",
       "      <td>2025-07-08</td>\n",
       "      <td>Oeste</td>\n",
       "      <td>1670.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>66.78</td>\n",
       "      <td>Hogar</td>\n",
       "      <td>2025-07-08</td>\n",
       "      <td>Oeste</td>\n",
       "      <td>133.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   producto_id  cantidad  precio_unitario        categoria fecha_venta  \\\n",
       "0           52         4           367.21  Electru00f3nica  2025-07-08   \n",
       "1           93        14           387.92         Deportes  2025-07-08   \n",
       "2           15        18            46.28         Juguetes  2025-07-08   \n",
       "3           72         9           185.65  Electru00f3nica  2025-07-08   \n",
       "4           61         2            66.78            Hogar  2025-07-08   \n",
       "\n",
       "   region  total_venta  \n",
       "0    Este      1468.84  \n",
       "1  Centro      5430.88  \n",
       "2    Este       833.04  \n",
       "3   Oeste      1670.85  \n",
       "4   Oeste       133.56  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear datos de ejemplo\n",
    "np.random.seed(42)  # Para reproducibilidad\n",
    "\n",
    "# Crear un DataFrame con datos simulados de ventas\n",
    "data = {\n",
    "    'producto_id': np.random.randint(1, 100, 50),\n",
    "    'cantidad': np.random.randint(1, 20, 50),\n",
    "    'precio_unitario': np.random.uniform(10.0, 500.0, 50).round(2),\n",
    "    'categoria': np.random.choice(['Electru00f3nica', 'Ropa', 'Hogar', 'Deportes', 'Juguetes'], 50),\n",
    "    'fecha_venta': [datetime.now().strftime('%Y-%m-%d') for _ in range(50)],\n",
    "    'region': np.random.choice(['Norte', 'Sur', 'Este', 'Oeste', 'Centro'], 50)\n",
    "}\n",
    "\n",
    "# Calcular el total de la venta\n",
    "df = pd.DataFrame(data)\n",
    "df['total_venta'] = df['cantidad'] * df['precio_unitario']\n",
    "\n",
    "# Mostrar los primeros registros\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos guardados en ../data/raw/ventas_ejemplo.csv\n"
     ]
    }
   ],
   "source": [
    "# Guardar en un archivo CSV\n",
    "csv_path = '../data/raw/ventas_ejemplo.csv'\n",
    "\n",
    "# Asegurar que el directorio existe\n",
    "os.makedirs(os.path.dirname(csv_path), exist_ok=True)\n",
    "\n",
    "# Guardar el DataFrame\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Datos guardados en {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from CSV file... prueba de volumen\n",
      "Se extrajeron 50 registros del archivo CSV.\n"
     ]
    }
   ],
   "source": [
    "# Extraer datos del CSV utilizando nuestra funciu00f3n extract_from_csv\n",
    "num_records = extract_from_csv(csv_path, 'ventas_csv')\n",
    "\n",
    "print(f\"Se extrajeron {num_records} registros del archivo CSV.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambiu00e9n podemos simular la extracciu00f3n desde una API (aunque en este caso crearemos datos ficticios):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos de API simulada insertados en raw_data.\n"
     ]
    }
   ],
   "source": [
    "# Simular datos de una API\n",
    "# En un caso real, usaru00edamos extract_from_api con una URL real\n",
    "\n",
    "# Función para convertir tipos NumPy a tipos nativos de Python\n",
    "def numpy_to_python(obj):\n",
    "    \"\"\"Convierte tipos de NumPy a tipos nativos de Python para serialización JSON\"\"\"\n",
    "    if isinstance(obj, (np.integer)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, (np.floating)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, pd.Series):\n",
    "        return obj.to_dict()\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# Crear datos simulados de una API\n",
    "api_data = {\n",
    "    'resumen_ventas': {\n",
    "        'total_ventas': df['total_venta'].sum(),\n",
    "        'promedio_venta': df['total_venta'].mean(),\n",
    "        'max_venta': df['total_venta'].max(),\n",
    "        'min_venta': df['total_venta'].min(),\n",
    "        'total_productos': df['cantidad'].sum(),\n",
    "        'fecha_reporte': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    },\n",
    "    'ventas_por_categoria': df.groupby('categoria')['total_venta'].sum().to_dict(),\n",
    "    'ventas_por_region': df.groupby('region')['total_venta'].sum().to_dict()\n",
    "}\n",
    "\n",
    "# En un caso real, estos datos vendru00edan de una API\n",
    "# Pero aquu00ed los insertamos directamente\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(\n",
    "        text(\"INSERT INTO raw_data (timestamp, source, data) VALUES (:timestamp, :source, :data)\"),\n",
    "        {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'source': 'api_simulada',\n",
    "            'data': json.dumps(api_data, default=numpy_to_python)\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"Datos de API simulada insertados en raw_data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos los datos extraidos en la tabla raw_data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-05-18 23:51:50.303212+00:00</td>\n",
       "      <td>ejemplo_notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-05-18 23:51:50.323238+00:00</td>\n",
       "      <td>ejemplo_notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-05-18 23:51:50.325509+00:00</td>\n",
       "      <td>ejemplo_notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2025-05-18 23:51:50.328453+00:00</td>\n",
       "      <td>ejemplo_notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2025-05-18 23:51:50.330390+00:00</td>\n",
       "      <td>ejemplo_notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>138</td>\n",
       "      <td>2025-07-08 00:01:20.424112+00:00</td>\n",
       "      <td>ventas_csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>139</td>\n",
       "      <td>2025-07-08 00:01:20.424149+00:00</td>\n",
       "      <td>ventas_csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>140</td>\n",
       "      <td>2025-07-08 00:01:20.424186+00:00</td>\n",
       "      <td>ventas_csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>141</td>\n",
       "      <td>2025-07-08 00:01:20.424223+00:00</td>\n",
       "      <td>ventas_csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>142</td>\n",
       "      <td>2025-07-08 00:12:04.526752+00:00</td>\n",
       "      <td>api_simulada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                        timestamp            source\n",
       "0      1 2025-05-18 23:51:50.303212+00:00  ejemplo_notebook\n",
       "1      2 2025-05-18 23:51:50.323238+00:00  ejemplo_notebook\n",
       "2      3 2025-05-18 23:51:50.325509+00:00  ejemplo_notebook\n",
       "3      4 2025-05-18 23:51:50.328453+00:00  ejemplo_notebook\n",
       "4      5 2025-05-18 23:51:50.330390+00:00  ejemplo_notebook\n",
       "..   ...                              ...               ...\n",
       "137  138 2025-07-08 00:01:20.424112+00:00        ventas_csv\n",
       "138  139 2025-07-08 00:01:20.424149+00:00        ventas_csv\n",
       "139  140 2025-07-08 00:01:20.424186+00:00        ventas_csv\n",
       "140  141 2025-07-08 00:01:20.424223+00:00        ventas_csv\n",
       "141  142 2025-07-08 00:12:04.526752+00:00      api_simulada\n",
       "\n",
       "[142 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Consultar datos de raw_data\n",
    "query = text(\"SELECT id, timestamp, source FROM raw_data\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    raw_data_summary = pd.read_sql(query, conn)\n",
    "\n",
    "raw_data_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transformaciu00f3n (Transform)\n",
    "\n",
    "Ahora vamos a transformar los datos utilizando nuestra funciu00f3n transform_raw_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al transformar datos: the JSON object must be str, bytes or bytearray, not dict\n",
      "Se transformaron 0 registros.\n"
     ]
    }
   ],
   "source": [
    "# Transformar todos los datos no procesados\n",
    "num_transformed = transform_raw_data()\n",
    "\n",
    "print(f\"Se transformaron {num_transformed} registros.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consultar datos transformados\n",
    "query = text(\"\"\"\n",
    "    SELECT p.id, r.source, p.processed_at\n",
    "    FROM processed_data p\n",
    "    JOIN raw_data r ON p.raw_data_id = r.id\n",
    "\"\"\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    processed_data_summary = pd.read_sql(query, conn)\n",
    "\n",
    "processed_data_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examinemos los datos transformados con mu00e1s detalle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consultar datos de ventas transformados\n",
    "query = text(\"\"\"\n",
    "    SELECT p.id, r.source, p.data\n",
    "    FROM processed_data p\n",
    "    JOIN raw_data r ON p.raw_data_id = r.id\n",
    "    WHERE r.source = 'ventas_csv'\n",
    "    LIMIT 5\n",
    "\"\"\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    ventas_processed = pd.read_sql(query, conn)\n",
    "\n",
    "# Extraer JSON para visualizaciu00f3n\n",
    "for i, row in ventas_processed.iterrows():\n",
    "    data = json.loads(row['data'])\n",
    "    print(f\"Registro {i+1}:{json.dumps(data, indent=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Carga (Load)\n",
    "\n",
    "Finalmente, vamos a cargar los datos transformados en la tabla final_data y generar insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos transformados en la tabla final\n",
    "num_loaded = load_to_final_table()\n",
    "\n",
    "print(f\"Se cargaron {num_loaded} registros en la tabla final.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consultar datos finales\n",
    "query = text(\"\"\"\n",
    "    SELECT f.id, r.source, f.metrics, f.insights\n",
    "    FROM final_data f\n",
    "    JOIN processed_data p ON f.processed_data_id = p.id\n",
    "    JOIN raw_data r ON p.raw_data_id = r.id\n",
    "\"\"\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    final_data = pd.read_sql(query, conn)\n",
    "\n",
    "final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a analizar los datos de ventas finales con mu00e1s detalle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer mu00e9tricas de ventas\n",
    "ventas_metrics = []\n",
    "\n",
    "for _, row in final_data.iterrows():\n",
    "    if row['source'] == 'ventas_csv':\n",
    "        metrics = json.loads(row['metrics'])\n",
    "        metrics['id'] = row['id']\n",
    "        ventas_metrics.append(metrics)\n",
    "\n",
    "# Convertir a DataFrame para anu00e1lisis\n",
    "if ventas_metrics:\n",
    "    ventas_df = pd.DataFrame(ventas_metrics)\n",
    "    \n",
    "    # Mostrar estadu00edsticas descriptivas\n",
    "    print(\"Estadu00edsticas descriptivas de las ventas:\")\n",
    "    print(ventas_df.describe())\n",
    "    \n",
    "    # Visualizar datos\n",
    "    if 'categoria' in ventas_df.columns and 'total_venta' in ventas_df.columns:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Ventas por categoru00eda\n",
    "        ventas_por_categoria = ventas_df.groupby('categoria')['total_venta'].sum().sort_values(ascending=False)\n",
    "        \n",
    "        plt.bar(ventas_por_categoria.index, ventas_por_categoria.values)\n",
    "        plt.title('Ventas Totales por Categoru00eda')\n",
    "        plt.xlabel('Categoru00eda')\n",
    "        plt.ylabel('Ventas Totales')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No hay datos de ventas disponibles para analizar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Resumen del Proceso ETL\n",
    "\n",
    "Vamos a crear un resumen del proceso ETL completo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consultar conteos de cada tabla\n",
    "with engine.connect() as conn:\n",
    "    raw_count = conn.execute(text(\"SELECT COUNT(*) FROM raw_data\")).scalar()\n",
    "    processed_count = conn.execute(text(\"SELECT COUNT(*) FROM processed_data\")).scalar()\n",
    "    final_count = conn.execute(text(\"SELECT COUNT(*) FROM final_data\")).scalar()\n",
    "\n",
    "# Crear DataFrame de resumen\n",
    "summary_data = {\n",
    "    'Etapa': ['Extracciu00f3n (raw_data)', 'Transformaciu00f3n (processed_data)', 'Carga (final_data)'],\n",
    "    'Registros': [raw_count, processed_count, final_count]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Mostrar resumen\n",
    "print(\"Resumen del Proceso ETL:\")\n",
    "print(summary_df)\n",
    "\n",
    "# Visualizar resumen\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(summary_df['Etapa'], summary_df['Registros'])\n",
    "plt.title('Registros por Etapa del Proceso ETL')\n",
    "plt.xlabel('Etapa')\n",
    "plt.ylabel('Nu00famero de Registros')\n",
    "plt.xticks(rotation=15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiu00f3n\n",
    "\n",
    "En este notebook, hemos implementado un proceso ETL completo utilizando nuestro framework de ingenieru00eda de datos:\n",
    "\n",
    "1. **Extracciu00f3n (Extract)**: Extrajimos datos de un archivo CSV y simulamos la extracciu00f3n desde una API.\n",
    "\n",
    "2. **Transformaciu00f3n (Transform)**: Transformamos los datos crudos aplicando limpieza y normalizaciu00f3n.\n",
    "\n",
    "3. **Carga (Load)**: Cargamos los datos transformados en la tabla final y generamos insights.\n",
    "\n",
    "Este flujo de trabajo puede ser adaptado para diferentes fuentes de datos y requisitos de procesamiento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
