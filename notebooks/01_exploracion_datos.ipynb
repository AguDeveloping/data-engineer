{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploración de Datos\n",
    "\n",
    "Este notebook muestra cómo conectarse a la base de datos PostgreSQL y realizar una exploración inicial de los datos.\n",
    "\n",
    "## Configuración del entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine, text\n",
    "import json\n",
    "\n",
    "# Configurar visualizaciones\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
    "\n",
    "# Configurar opciones de pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conexión a la base de datos\n",
    "\n",
    "Primero, establecemos la conexión con nuestra base de datos PostgreSQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexión establecida con la base de datos.\n"
     ]
    }
   ],
   "source": [
    "# Conectar a la base de datos\n",
    "DATABASE_URL = \"postgresql://postgres:postgres@db:5432/dataengineering\"\n",
    "engine = create_engine(DATABASE_URL)\n",
    "connection = engine.connect()\n",
    "\n",
    "print(\"Conexión establecida con la base de datos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificar las tablas disponibles\n",
    "\n",
    "Vamos a verificar qué tablas están disponibles en nuestra base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>raw_data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>processed_data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>final_data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cache_config</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>databasechangelog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Genre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>MediaType</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Artist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Album</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Track</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            table_name\n",
       "0             raw_data\n",
       "1       processed_data\n",
       "2           final_data\n",
       "3         cache_config\n",
       "4    databasechangelog\n",
       "..                 ...\n",
       "114              Genre\n",
       "115          MediaType\n",
       "116             Artist\n",
       "117              Album\n",
       "118              Track\n",
       "\n",
       "[119 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Consultar las tablas disponibles\n",
    "query = text(\"\"\"\n",
    "    SELECT table_name \n",
    "    FROM information_schema.tables \n",
    "    WHERE table_schema = 'public'\n",
    "\"\"\")\n",
    "\n",
    "tables = pd.read_sql(query, connection)\n",
    "tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar datos de ejemplo\n",
    "\n",
    "Para este ejemplo, vamos a crear algunos datos de prueba y cargarlos en la tabla `raw_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>valor</th>\n",
       "      <th>categoria</th>\n",
       "      <th>fecha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>B</td>\n",
       "      <td>2025-07-07 22:54:46.906768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>89</td>\n",
       "      <td>A</td>\n",
       "      <td>2025-07-06 22:54:46.906778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>C</td>\n",
       "      <td>2025-07-05 22:54:46.906780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>B</td>\n",
       "      <td>2025-07-04 22:54:46.906782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>A</td>\n",
       "      <td>2025-07-03 22:54:46.906783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>84</td>\n",
       "      <td>B</td>\n",
       "      <td>2025-07-02 22:54:46.906784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>A</td>\n",
       "      <td>2025-07-01 22:54:46.906786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>B</td>\n",
       "      <td>2025-06-30 22:54:46.906787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>54</td>\n",
       "      <td>B</td>\n",
       "      <td>2025-06-29 22:54:46.906788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "      <td>A</td>\n",
       "      <td>2025-06-28 22:54:46.906790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  valor categoria                      fecha\n",
       "0   1     68         B 2025-07-07 22:54:46.906768\n",
       "1   2     89         A 2025-07-06 22:54:46.906778\n",
       "2   3     59         C 2025-07-05 22:54:46.906780\n",
       "3   4     51         B 2025-07-04 22:54:46.906782\n",
       "4   5     60         A 2025-07-03 22:54:46.906783\n",
       "5   6     84         B 2025-07-02 22:54:46.906784\n",
       "6   7     43         A 2025-07-01 22:54:46.906786\n",
       "7   8     19         B 2025-06-30 22:54:46.906787\n",
       "8   9     54         B 2025-06-29 22:54:46.906788\n",
       "9  10     45         A 2025-06-28 22:54:46.906790"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear datos de ejemplo\n",
    "import datetime\n",
    "\n",
    "# Crear un DataFrame de ejemplo\n",
    "data = {\n",
    "    'id': range(1, 11),\n",
    "    'valor': np.random.randint(10, 100, 10),\n",
    "    'categoria': np.random.choice(['A', 'B', 'C'], 10),\n",
    "    'fecha': [datetime.datetime.now() - datetime.timedelta(days=i) for i in range(10)]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos insertados correctamente en la tabla raw_data.\n"
     ]
    }
   ],
   "source": [
    "# Insertar datos en la tabla raw_data\n",
    "for _, row in df.iterrows():\n",
    "    # Convertir el timestamp a string para que sea serializable\n",
    "    row_dict = row.to_dict()\n",
    "    \n",
    "    # Convertir el objeto Timestamp a string si existe\n",
    "    if 'fecha' in row_dict:\n",
    "        row_dict['fecha'] = str(row_dict['fecha'])\n",
    "    \n",
    "    # Convertir a formato JSON\n",
    "    data_json = json.dumps(row_dict)\n",
    "    \n",
    "    # Preparar la consulta de inserción\n",
    "    insert_query = text(\"\"\"\n",
    "        INSERT INTO raw_data (timestamp, source, data)\n",
    "        VALUES (:timestamp, :source, :data)\n",
    "    \"\"\")\n",
    "    \n",
    "    # Ejecutar la consulta\n",
    "    connection.execute(insert_query, {\n",
    "        'timestamp': datetime.datetime.now(),\n",
    "        'source': 'ejemplo_notebook',\n",
    "        'data': data_json\n",
    "    })\n",
    "\n",
    "print(\"Datos insertados correctamente en la tabla raw_data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consultar datos de la tabla raw_data\n",
    "\n",
    "Ahora vamos a consultar los datos que acabamos de insertar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-05-18 23:51:50.303212+00:00</td>\n",
       "      <td>ejemplo_notebook</td>\n",
       "      <td>{'id': 1, 'fecha': '2025-05-18 23:39:46.137472...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-05-18 23:51:50.323238+00:00</td>\n",
       "      <td>ejemplo_notebook</td>\n",
       "      <td>{'id': 2, 'fecha': '2025-05-17 23:39:46.137484...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-05-18 23:51:50.325509+00:00</td>\n",
       "      <td>ejemplo_notebook</td>\n",
       "      <td>{'id': 3, 'fecha': '2025-05-16 23:39:46.137487...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2025-05-18 23:51:50.328453+00:00</td>\n",
       "      <td>ejemplo_notebook</td>\n",
       "      <td>{'id': 4, 'fecha': '2025-05-15 23:39:46.137489...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2025-05-18 23:51:50.330390+00:00</td>\n",
       "      <td>ejemplo_notebook</td>\n",
       "      <td>{'id': 5, 'fecha': '2025-05-14 23:39:46.137491...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2025-05-18 23:51:50.332393+00:00</td>\n",
       "      <td>ejemplo_notebook</td>\n",
       "      <td>{'id': 6, 'fecha': '2025-05-13 23:39:46.137493...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-05-18 23:51:50.334153+00:00</td>\n",
       "      <td>ejemplo_notebook</td>\n",
       "      <td>{'id': 7, 'fecha': '2025-05-12 23:39:46.137495...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2025-05-18 23:51:50.336348+00:00</td>\n",
       "      <td>ejemplo_notebook</td>\n",
       "      <td>{'id': 8, 'fecha': '2025-05-11 23:39:46.137496...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2025-05-18 23:51:50.338515+00:00</td>\n",
       "      <td>ejemplo_notebook</td>\n",
       "      <td>{'id': 9, 'fecha': '2025-05-10 23:39:46.137498...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2025-05-18 23:51:50.340399+00:00</td>\n",
       "      <td>ejemplo_notebook</td>\n",
       "      <td>{'id': 10, 'fecha': '2025-05-09 23:39:46.13750...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                        timestamp            source                                               data\n",
       "0   1 2025-05-18 23:51:50.303212+00:00  ejemplo_notebook  {'id': 1, 'fecha': '2025-05-18 23:39:46.137472...\n",
       "1   2 2025-05-18 23:51:50.323238+00:00  ejemplo_notebook  {'id': 2, 'fecha': '2025-05-17 23:39:46.137484...\n",
       "2   3 2025-05-18 23:51:50.325509+00:00  ejemplo_notebook  {'id': 3, 'fecha': '2025-05-16 23:39:46.137487...\n",
       "3   4 2025-05-18 23:51:50.328453+00:00  ejemplo_notebook  {'id': 4, 'fecha': '2025-05-15 23:39:46.137489...\n",
       "4   5 2025-05-18 23:51:50.330390+00:00  ejemplo_notebook  {'id': 5, 'fecha': '2025-05-14 23:39:46.137491...\n",
       "5   6 2025-05-18 23:51:50.332393+00:00  ejemplo_notebook  {'id': 6, 'fecha': '2025-05-13 23:39:46.137493...\n",
       "6   7 2025-05-18 23:51:50.334153+00:00  ejemplo_notebook  {'id': 7, 'fecha': '2025-05-12 23:39:46.137495...\n",
       "7   8 2025-05-18 23:51:50.336348+00:00  ejemplo_notebook  {'id': 8, 'fecha': '2025-05-11 23:39:46.137496...\n",
       "8   9 2025-05-18 23:51:50.338515+00:00  ejemplo_notebook  {'id': 9, 'fecha': '2025-05-10 23:39:46.137498...\n",
       "9  10 2025-05-18 23:51:50.340399+00:00  ejemplo_notebook  {'id': 10, 'fecha': '2025-05-09 23:39:46.13750..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Consultar datos de raw_data\n",
    "query = text(\"SELECT id, timestamp, source, data FROM raw_data LIMIT 10\")\n",
    "raw_data = pd.read_sql(query, connection)\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesar los datos\n",
    "\n",
    "Vamos a procesar los datos y almacenarlos en la tabla `processed_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "the JSON object must be str, bytes or bytearray, not dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Procesar los datos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m raw_data\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Extraer el JSON de la columna data\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Realizar alguna transformación (ejemplo: duplicar el valor)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalor\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/json/__init__.py:339\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(s, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mbytearray\u001b[39m)):\n\u001b[0;32m--> 339\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe JSON object must be str, bytes or bytearray, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    340\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n",
      "\u001b[0;31mTypeError\u001b[0m: the JSON object must be str, bytes or bytearray, not dict"
     ]
    }
   ],
   "source": [
    "# Procesar los datos\n",
    "for _, row in raw_data.iterrows():\n",
    "    # Extraer el JSON de la columna data\n",
    "    data = json.loads(row['data'])\n",
    "    \n",
    "    # Realizar alguna transformación (ejemplo: duplicar el valor)\n",
    "    if 'valor' in data:\n",
    "        data['valor_duplicado'] = data['valor'] * 2\n",
    "    \n",
    "    # Convertir a formato JSON\n",
    "    processed_data_json = json.dumps(data)\n",
    "    \n",
    "    # Insertar en la tabla processed_data\n",
    "    insert_query = text(\"\"\"\n",
    "        INSERT INTO processed_data (raw_data_id, data)\n",
    "        VALUES (:raw_data_id, :data)\n",
    "    \"\"\")\n",
    "    \n",
    "    connection.execute(insert_query, {\n",
    "        'raw_data_id': row['id'],\n",
    "        'data': processed_data_json\n",
    "    })\n",
    "\n",
    "print(\"Datos procesados correctamente y almacenados en la tabla processed_data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consultar datos procesados\n",
    "\n",
    "Ahora vamos a consultar los datos procesados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consultar datos de processed_data\n",
    "query = text(\"\"\"\n",
    "    SELECT p.id, p.raw_data_id, p.processed_at, p.data\n",
    "    FROM processed_data p\n",
    "    JOIN raw_data r ON p.raw_data_id = r.id\n",
    "    LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "processed_data = pd.read_sql(query, connection)\n",
    "processed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis exploratorio\n",
    "\n",
    "Vamos a realizar un análisis exploratorio básico de los datos procesados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer los datos JSON en un DataFrame\n",
    "data_list = []\n",
    "\n",
    "for _, row in processed_data.iterrows():\n",
    "    data_dict = json.loads(row['data'])\n",
    "    data_dict['processed_id'] = row['id']  # Agregar el ID del registro procesado\n",
    "    data_list.append(data_dict)\n",
    "\n",
    "# Crear DataFrame\n",
    "analysis_df = pd.DataFrame(data_list)\n",
    "analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis estadístico básico\n",
    "analysis_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización: Distribución de valores\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(analysis_df['valor'], kde=True)\n",
    "plt.title('Distribución de Valores Originales')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(analysis_df['valor_duplicado'], kde=True)\n",
    "plt.title('Distribución de Valores Duplicados')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización: Valores por categoría\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(x='categoria', y='valor', data=analysis_df)\n",
    "plt.title('Valores por Categoría')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(x='categoria', y='valor_duplicado', data=analysis_df)\n",
    "plt.title('Valores Duplicados por Categoría')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generar insights y cargar en la tabla final_data\n",
    "\n",
    "Finalmente, vamos a generar algunos insights y cargarlos en la tabla `final_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular métricas por categoría\n",
    "category_metrics = analysis_df.groupby('categoria').agg({\n",
    "    'valor': ['mean', 'min', 'max', 'std'],\n",
    "    'valor_duplicado': ['mean', 'min', 'max', 'std']\n",
    "})\n",
    "\n",
    "category_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insertar insights en la tabla final_data\n",
    "for processed_id in processed_data['id']:\n",
    "    # Obtener los datos procesados\n",
    "    processed_row = processed_data[processed_data['id'] == processed_id].iloc[0]\n",
    "    processed_data_dict = json.loads(processed_row['data'])\n",
    "    \n",
    "    # Extraer la categoría\n",
    "    categoria = processed_data_dict.get('categoria', 'Desconocida')\n",
    "    \n",
    "    # Calcular métricas\n",
    "    if 'valor' in processed_data_dict:\n",
    "        valor = processed_data_dict['valor']\n",
    "        valor_duplicado = processed_data_dict.get('valor_duplicado', 0)\n",
    "        \n",
    "        # Crear métricas\n",
    "        metrics = {\n",
    "            'valor_original': valor,\n",
    "            'valor_duplicado': valor_duplicado,\n",
    "            'diferencia': valor_duplicado - valor,\n",
    "            'categoria': categoria\n",
    "        }\n",
    "        \n",
    "        # Generar insights\n",
    "        insights = f\"El valor {valor} de la categoría {categoria} fue duplicado a {valor_duplicado}. \"\n",
    "        \n",
    "        # Comparar con el promedio de la categoría\n",
    "        if categoria in category_metrics.index:\n",
    "            avg_valor = category_metrics.loc[categoria, ('valor', 'mean')]\n",
    "            if valor > avg_valor:\n",
    "                insights += f\"El valor está por encima del promedio de la categoría ({avg_valor:.2f}).\"\n",
    "            else:\n",
    "                insights += f\"El valor está por debajo del promedio de la categoría ({avg_valor:.2f}).\"\n",
    "        \n",
    "        # Insertar en la tabla final_data\n",
    "        insert_query = text(\"\"\"\n",
    "            INSERT INTO final_data (processed_data_id, metrics, insights)\n",
    "            VALUES (:processed_data_id, :metrics, :insights)\n",
    "        \"\"\")\n",
    "        \n",
    "        connection.execute(insert_query, {\n",
    "            'processed_data_id': processed_id,\n",
    "            'metrics': json.dumps(metrics),\n",
    "            'insights': insights\n",
    "        })\n",
    "\n",
    "print(\"Insights generados y almacenados en la tabla final_data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consultar datos finales\n",
    "\n",
    "Por último, vamos a consultar los datos finales con sus insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consultar datos de final_data\n",
    "query = text(\"\"\"\n",
    "    SELECT f.id, f.processed_data_id, f.created_at, f.metrics, f.insights\n",
    "    FROM final_data f\n",
    "    JOIN processed_data p ON f.processed_data_id = p.id\n",
    "    LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "final_data = pd.read_sql(query, connection)\n",
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer métricas para análisis\n",
    "metrics_list = []\n",
    "\n",
    "for _, row in final_data.iterrows():\n",
    "    metrics_dict = json.loads(row['metrics'])\n",
    "    metrics_dict['final_id'] = row['id']\n",
    "    metrics_dict['insights'] = row['insights']\n",
    "    metrics_list.append(metrics_dict)\n",
    "\n",
    "# Crear DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización final: Comparación de valores originales y duplicados\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Crear datos para el gráfico\n",
    "x = range(len(metrics_df))\n",
    "\n",
    "plt.bar(x, metrics_df['valor_original'], width=0.4, align='edge', label='Valor Original')\n",
    "plt.bar([i+0.4 for i in x], metrics_df['valor_duplicado'], width=0.4, align='edge', label='Valor Duplicado')\n",
    "\n",
    "plt.xlabel('Registro')\n",
    "plt.ylabel('Valor')\n",
    "plt.title('Comparación de Valores Originales y Duplicados')\n",
    "plt.legend()\n",
    "plt.xticks([i+0.2 for i in x], metrics_df['final_id'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cerrar la conexión\n",
    "\n",
    "Finalmente, cerramos la conexión a la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cerrar la conexión\n",
    "connection.close()\n",
    "print(\"Conexión cerrada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titulo de ejemplo custom: nueva tarea ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# este es un ejemplo de notebook con codigo de comentarios."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
